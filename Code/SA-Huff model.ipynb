{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct distance matrix and attractiveness matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate travel distance (in km) using google map distance matrix api\n",
    "import googlemaps\n",
    "API_key = 'AIzaSyBRtFBIA_8WBGTxDLxp1SLMrT3sYsMccwA'\n",
    "gmaps = googlemaps.Client(key=API_key)\n",
    "\n",
    "def get_dist_matrix(df):\n",
    "\n",
    "    destinations = df.coord\n",
    "    names = df['Clusters from Data'].values\n",
    "    \n",
    "    dim = len(destinations)\n",
    "    dist_matrix = np.zeros((dim, dim), float)\n",
    "    \n",
    "    \n",
    "    for i in range(dim):\n",
    "        actual_distance = []\n",
    "        origin = destinations[i]        \n",
    "        for destination in destinations:\n",
    "            result = gmaps.distance_matrix(origin, destination, mode='driving')['rows'][0]['elements'][0]['distance']['value']\n",
    "            result = result/1000\n",
    "            actual_distance.append(result)\n",
    "        dist_matrix[i] = actual_distance\n",
    "        \n",
    "    res = pd.DataFrame(data=dist_matrix, index = names, columns=names)\n",
    "    return res\n",
    "\n",
    "# generate attractiveness matrix\n",
    "def attr_matrix(df, month):\n",
    "    attr_matrix = pd.DataFrame()\n",
    "    df = subset_data(df, month)\n",
    "    \n",
    "    attr_matrix['Places'] = position['Clusters from Data'].values\n",
    "    attr_matrix['photo_views'] = df.groupby(['Cluster'])['views'].agg('sum')\n",
    "    attr_matrix['num_uploaders'] = df.groupby(['Cluster'])['owner'].nunique()\n",
    "    attr_matrix['num_of_photos'] = df.groupby(['Cluster']).size()\n",
    "    attr_matrix['avg_view_per_user'] = attr_matrix['photo_views']/attr_matrix['num_uploaders']\n",
    "    attr_matrix['avg_view_per_photo'] = attr_matrix['photo_views']/attr_matrix['num_of_photos']\n",
    "    attr_matrix['total_attr'] = attr_matrix['num_of_photos'] * attr_matrix['avg_view_per_user']\n",
    "    attr_matrix = attr_matrix.fillna(0)\n",
    "    attr_matrix['total_attr_log'] = np.log(attr_matrix['total_attr']+1)\n",
    "    attr_matrix = attr_matrix.set_index('Places')\n",
    "    return attr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to include the neighboring effect\n",
    "# select K neighbors\n",
    "def neighbors(dest, dist_matrix, K):\n",
    "    destinations = dist_matrix.index.values\n",
    "    dist_tp = np.transpose(dist_matrix)\n",
    "    neighbors = dist_tp.nsmallest(10, [dest])[1:K+1].index.values   \n",
    "    return neighbors\n",
    "\n",
    "# calculate centrality score based on K neighbors, attraction matrix and distance matrix\n",
    "def centrality(dest, attr_matrix, K):\n",
    "    neighbor_lst = neighbors(dest, dist_matrix, K)\n",
    "    c = 0\n",
    "    dist = 0\n",
    "    for p in neighbor_lst:\n",
    "        c += attr_matrix.loc[p]['total_attr_log']/dist_matrix.loc[dest][p]\n",
    "        dist += dist_matrix.loc[dest][p]\n",
    "        c = c/dist\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary Least Squares (OLS) Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getComplement(item, lst):\n",
    "    results = []\n",
    "    for num in lst:\n",
    "        if num != item: \n",
    "            results.append(num)\n",
    "    return results\n",
    "\n",
    "# OLS dependent variable\n",
    "def read_actual(pmatrix, origin):\n",
    "    num = 0\n",
    "    denom = 0\n",
    "    result = []\n",
    "    places = position['Clusters from Data'].values\n",
    "    dests = getComplement(origin, places)   \n",
    "    actual_pmatrix = pd.read_csv(pmatrix, index_col=0)\n",
    "    for i in range(len(dests)):\n",
    "        num = actual_pmatrix.loc[origin].values[i]\n",
    "        denom = np.mean(actual_pmatrix.loc[origin])\n",
    "        result.append(num/denom)\n",
    "    return result\n",
    "\n",
    "# OLS independent variables\n",
    "# attractiveness (including Social Influence), distance, centrality\n",
    "def log_transform_x(origin,K,month):\n",
    "    X1, X2, X3 = [],[],[]\n",
    "    total_centrality = 0\n",
    "    places = position['Clusters from Data'].values\n",
    "    dests = getComplement(origin, places)\n",
    "    attr_mat = attr_matrix(df, month)\n",
    "    for dest in dests:\n",
    "        total_centrality += centrality(dest, attr_mat, K)\n",
    "        X1.append(attr_mat.loc[dest]['total_attr_log']/np.mean(attr_mat['total_attr_log']))\n",
    "        X2.append(dist_matrix.loc[origin][dest]/ np.mean(dist_matrix.loc[origin]))\n",
    "        X3.append(centrality(dest, attr_mat, K)/(total_centrality/len(dests)))\n",
    "    var_table = pd.DataFrame()\n",
    "    X1 = [x + 1 for x in X1]\n",
    "    X3 = [x + 1 for x in X3]\n",
    "    var_table['x1'] = np.nan_to_num(np.log(X1))\n",
    "    var_table['x2'] = np.nan_to_num(np.log(X2))\n",
    "    var_table['x3'] = np.nan_to_num(np.log(X3))\n",
    "    return var_table\n",
    "\n",
    "## fit a OLS model on the three parameters\n",
    "df_allmonth['Y'] = Y_res\n",
    "df_allmonth = df_allmonth[df_allmonth.Y > 0]\n",
    "\n",
    "X = df_allmonth[['x1', 'x2','x3']]\n",
    "Y = df_allmonth['Y']\n",
    "\n",
    "results = sm.OLS(Y,X).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compare with the classic Huff model with time\n",
    "def Huff_Model(df, origin, dest,alpha, beta, month):\n",
    "    places = position['Clusters from Data'].values\n",
    "    dests = getComplement(origin, places)    \n",
    "    denom = 0\n",
    "    attr_mat = attr_matrix(df, month)\n",
    "    if dist_matrix.loc[origin][dest] > 0:\n",
    "        numer = (attr_mat.loc[dest]['total_attr_log']**alpha) * (dist_matrix.loc[origin][dest]**beta)\n",
    "    else:\n",
    "        numer = 0\n",
    "    for dest in dests:\n",
    "        denom += (attr_mat.loc[dest]['total_attr_log']**alpha) * (dist_matrix.loc[origin][dest]**beta)\n",
    "    return numer/denom\n",
    "\n",
    "## SA-Huff Model with time and centrality\n",
    "def Huff_Model_with_centrality(df, origin, dest, alpha, beta, theta, month, K):\n",
    "    places = position['Clusters from Data'].values\n",
    "    dests = getComplement(origin, places)    \n",
    "    denom = 0\n",
    "    attr_mat = attr_matrix(df, month)\n",
    "    if dist_matrix.loc[origin][dest] > 0:\n",
    "        numer = attr_mat.loc[dest]['total_attr_log']**alpha * (dist_matrix.loc[origin][dest]**beta) * centrality(dest, attr_mat, K)**theta\n",
    "    else:\n",
    "        numer = 0\n",
    "    for dest in dests:\n",
    "        denom += attr_mat.loc[dest]['total_attr_log']**alpha * (dist_matrix.loc[origin][dest]**beta) * centrality(dest, attr_mat, K)**theta\n",
    "    return numer/denom"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
